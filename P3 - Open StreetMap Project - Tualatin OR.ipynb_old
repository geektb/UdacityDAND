{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3 - Open StreetMap Project - Tualatin OR\n",
    "\n",
    "### Our first task is to parse the XML file from OpenStreetMaps and save it to CSV files.\n",
    "While we're doing that, we will also clean up our addresses and phone numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-10-07 09:21:54.387000: Starting XML file parsing\n",
      "2016-10-07 09:22:07.682000: CSV files created.\n",
      "It took the script 13.295 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "# Identify out XML file\n",
    "OSM_PATH = \"tualatin.osm\"\n",
    "\n",
    "# Create file paths for CSV files\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "# Define various Regular Expressions for value cleanup\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# These are the address suffix we're expecting\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Lane\", \"Road\", \"Loop\", \"Woods\",\n",
    "            \"Trail\", \"Parkway\", \"Circle\", \"Terrace\", \"Way\", \"Highway\", \"Path\"]\n",
    "\n",
    "# These are the suffixes we found in the file that need to be mapped to one of the above\n",
    "mapping = { \n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Dr.\": \"Drive\",\n",
    "            \"Rd\": \"Road\"\n",
    "          }\n",
    "\n",
    "# Here we define each CSV file's fields. This must match the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "\n",
    "#### This section cleans up and standardizes the addresses #####\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit_street_name(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                #if is_street_name(tag):\n",
    "                if tag.attrib['k'] == \"addr:street\":\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name):\n",
    "    name = name.split(' ')\n",
    "    type = name[-1]\n",
    "    if type in mapping:\n",
    "        name[-1] = mapping[type]\n",
    "        name = ' '.join(name)\n",
    "        return name\n",
    "    elif name == \"SW Upper Boones Ferry Rd #100\":\n",
    "        return \"SW Upper Boones Ferry Road #100\"\n",
    "    elif name == \"SW 74th\":\n",
    "        return \"SW 74th Avenue\"\n",
    "    elif name == \"SW 91st\":\n",
    "        return \"SW 91st Avenue\"\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "#### End of address cleanup functions #####\n",
    "\n",
    "\n",
    "\n",
    "# This function cleans up our phone numbers and removes country codes\n",
    "def clean_phone(phonenumber):\n",
    "    phonePattern = re.compile(r'''(\\d{3})\\D*(\\d{3})\\D*(\\d{4})\\D*(\\d*)$''')\n",
    "    phonenumber = phonePattern.search(phonenumber).group()\n",
    "    phonenumber = re.sub(\" \", \"-\", phonenumber)\n",
    "    phonenumber = re.sub(\"[()]\", \"\", phonenumber)\n",
    "    if re.match(r'\\d{11}', phonenumber) is not None:\n",
    "        phonenumber = phone_num[1:10]\n",
    "    return phonenumber\n",
    "\n",
    "\n",
    "# Load a new tag dict to go into the list of dicts for way_tags, node_tags\n",
    "def create_new_tag(element, secondlvl, default_tag_type):\n",
    "    newtag = {}\n",
    "    newtag['id'] = element.attrib['id']\n",
    "    if \":\" not in secondlvl.attrib['k']:\n",
    "        newtag['key'] = secondlvl.attrib['k']\n",
    "        newtag['type'] = default_tag_type\n",
    "    else:\n",
    "        post_colon = secondlvl.attrib['k'].index(\":\") + 1\n",
    "        newtag['key'] = secondlvl.attrib['k'][post_colon:]\n",
    "        newtag['type'] = secondlvl.attrib['k'][:post_colon - 1]\n",
    "\n",
    "    # Cleaning up street names\n",
    "    if is_street_name(secondlvl):\n",
    "        street_name = update_name(secondlvl.attrib['v'])\n",
    "        newtag['value'] = street_name\n",
    "    \n",
    "    # Cleaning up phone numbers\n",
    "    elif newtag['key'] == 'phone':\n",
    "        phone_number = clean_phone(secondlvl.attrib['v'])\n",
    "        if phone_number is not None:\n",
    "            newtag['value'] = phone_number\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        newtag['value'] = secondlvl.attrib['v']\n",
    "    return newtag\n",
    "\n",
    "\n",
    "#Clean and shape node or way XML element to Python dict\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle nested tags the same way for both node and way elements\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for attrib, value in element.attrib.iteritems():\n",
    "            if attrib in node_attr_fields:\n",
    "                node_attribs[attrib] = value\n",
    "        \n",
    "        # For elements within the top element\n",
    "        for secondlvl in element.iter():\n",
    "            if secondlvl.tag == 'tag':\n",
    "                if problem_chars.match(secondlvl.attrib['k']) is not None:\n",
    "                    continue\n",
    "                else:\n",
    "                    newtag = create_new_tag(element, secondlvl, default_tag_type)\n",
    "                    if newtag is not None:\n",
    "                        tags.append(newtag)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        for attrib, value in element.attrib.iteritems():\n",
    "            if attrib in way_attr_fields:\n",
    "                way_attribs[attrib] = value\n",
    "\n",
    "        counter = 0\n",
    "        for secondlvl in element.iter():\n",
    "            if secondlvl.tag == 'tag':\n",
    "                if problem_chars.match(secondlvl.attrib['k']) is not None:\n",
    "                    continue\n",
    "                else:\n",
    "                    newtag = create_new_tag(element, secondlvl, default_tag_type)\n",
    "                    if newtag is not None:\n",
    "                        tags.append(newtag)\n",
    "            elif secondlvl.tag == 'nd':\n",
    "                newnode = {}\n",
    "                newnode['id'] = element.attrib['id']\n",
    "                newnode['node_id'] = secondlvl.attrib['ref']\n",
    "                newnode['position'] = counter\n",
    "                counter += 1\n",
    "                way_nodes.append(newnode)\n",
    "        \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#      Helper Functions - Provided by uDacity        #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#         Main Function - Provided by uDacity        #\n",
    "# ================================================== #\n",
    "def process_map(file_in):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        # Removed writeheader() lines to resolve data type conversion issue when loading data\n",
    "        \"\"\"\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "        \"\"\"\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "                    \n",
    "                    \n",
    "if __name__ == '__main__':\n",
    "    start = datetime.now()\n",
    "    print str(start) + \": Starting XML file parsing\"\n",
    "    process_map(OSM_PATH)\n",
    "    end = datetime.now()\n",
    "    delta = end - start\n",
    "    print str(end) + \": CSV files created\"\n",
    "    print \"It took the script \" + str(delta.total_seconds()) + \" seconds to run\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ...and now we create a new SQLite DB and load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SQLLite Schema\n",
    "\n",
    "CREATE TABLE nodes (\n",
    "id INTEGER PRIMARY KEY NOT NULL,\n",
    "lat REAL,\n",
    "lon REAL,\n",
    "user TEXT,\n",
    "uid INTEGER,\n",
    "version INTEGER,\n",
    "changeset INTEGER,\n",
    "timestamp TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE nodes_tags (\n",
    "id INTEGER,\n",
    "key TEXT,\n",
    "value TEXT,\n",
    "type TEXT,\n",
    "FOREIGN KEY (id) REFERENCES nodes(id)\n",
    ");\n",
    "\n",
    "CREATE TABLE ways (\n",
    "id INTEGER PRIMARY KEY NOT NULL,\n",
    "user TEXT,\n",
    "uid INTEGER,\n",
    "version TEXT,\n",
    "changeset INTEGER,\n",
    "timestamp TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE ways_tags (\n",
    "id INTEGER NOT NULL,\n",
    "key TEXT NOT NULL,\n",
    "value TEXT NOT NULL,\n",
    "type TEXT,\n",
    "FOREIGN KEY (id) REFERENCES ways(id)\n",
    ");\n",
    "\n",
    "CREATE TABLE ways_nodes (\n",
    "id INTEGER NOT NULL,\n",
    "node_id INTEGER NOT NULL,\n",
    "position INTEGER NOT NULL,\n",
    "FOREIGN KEY (id) REFERENCES ways(id),\n",
    "FOREIGN KEY (node_id) REFERENCES nodes(id)\n",
    ");\n",
    "\n",
    "### Import CSV Tables in SQLite\n",
    "\n",
    ".mode csv\n",
    ".import nodes.csv nodes\n",
    ".import nodes_tags.csv nodes_tags\n",
    ".import ways.csv ways\n",
    ".import ways_tags.csv ways_tags\n",
    ".import ways_nodes.csv ways_nodes\n",
    "\n",
    "drop table nodes;\n",
    "drop table ways;\n",
    "drop table nodes_tags;\n",
    "drop table ways_tags;\n",
    "drop table ways_nodes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row data:\n",
      "[(5230539, u'Madeline Steele', 3645536, u'4', 40080052, u'2016-06-16T23:00:28Z\\r'), (5249976, u'Grant Humphries', 393906, u'30', 29884502, u'2015-03-31T18:13:12Z\\r'), (5250018, u'Grant Humphries', 393906, u'26', 14752539, u'2013-01-23T00:31:18Z\\r'), (5273203, u'Luis36995', 1829683, u'30', 39363622, u'2016-05-16T21:26:21Z\\r'), (5273547, u'Shana-Lynn Rogers', 1372934, u'2', 18443897, u'2013-10-20T01:51:08Z\\r'), (5273691, u'Shana-Lynn Rogers', 1372934, u'2', 18443897, u'2013-10-20T01:51:08Z\\r'), (5273742, u'betsy', 371688, u'3', 8859585, u'2011-07-28T23:55:13Z\\r'), (5274667, u'looshious', 120500, u'2', 8146428, u'2011-05-14T22:05:00Z\\r'), (5275237, u'Jothirnadh', 2015224, u'14', 39351384, u'2016-05-16T12:29:46Z\\r'), (5275626, u'Peter Dobratz_pdxbuildings', 2573347, u'2', 31814034, u'2015-06-08T12:56:16Z\\r')]\n",
      "\n",
      "ways:\n",
      "   5230539\n",
      "   5249976\n",
      "   5250018\n",
      "   5273203\n",
      "   5273547\n",
      "   5273691\n",
      "   5273742\n",
      "   5274667\n",
      "   5275237\n",
      "   5275626\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Fetch some student records from the database.\n",
    "db = sqlite3.connect(\"P3.db\")\n",
    "c = db.cursor()\n",
    "query = \"select * from ways limit 10;\"\n",
    "c.execute(query)\n",
    "rows = c.fetchall()\n",
    "\n",
    "# First, what data structure did we get?\n",
    "print \"Row data:\"\n",
    "print rows\n",
    "\n",
    "# And let's loop over it too:\n",
    "print\n",
    "print \"ways:\"\n",
    "for row in rows:\n",
    "  print \"  \", row[0]\n",
    "\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After auditing is complete the next step is to prepare the data to be inserted into a SQL database.\n",
    "To do so you will parse the elements in the OSM XML file, transforming them from document format to\n",
    "tabular format, thus making it possible to write to .csv files.  These csv files can then easily be\n",
    "imported to a SQL database as tables.\n",
    "The process for this transformation is as follows:\n",
    "- Use iterparse to iteratively step through each top level element in the XML\n",
    "- Shape each element into several data structures using a custom function\n",
    "- Utilize a schema and validation library to ensure the transformed data is in the correct format\n",
    "- Write each data structure to the appropriate .csv files\n",
    "We've already provided the code needed to load the data, perform iterative parsing and write the\n",
    "output to csv files. Your task is to complete the shape_element function that will transform each\n",
    "element into the correct format. To make this process easier we've already defined a schema (see\n",
    "the schema.py file in the last code tab) for the .csv files and the eventual tables. Using the \n",
    "cerberus library we can validate the output against this schema to ensure it is correct.\n",
    "\n",
    "## Shape Element Function\n",
    "The function should take as input an iterparse Element object and return a dictionary.\n",
    "\n",
    "### If the element top level tag is \"node\":\n",
    "The dictionary returned should have the format {\"node\": .., \"node_tags\": ...}\n",
    "The \"node\" field should hold a dictionary of the following top level node attributes:\n",
    "- id\n",
    "- user\n",
    "- uid\n",
    "- version\n",
    "- lat\n",
    "- lon\n",
    "- timestamp\n",
    "- changeset\n",
    "All other attributes can be ignored\n",
    "\n",
    "The \"node_tags\" field should hold a list of dictionaries, one per secondary tag. Secondary tags are\n",
    "child tags of node which have the tag name/type: \"tag\". Each dictionary should have the following\n",
    "fields from the secondary tag attributes:\n",
    "- id: the top level node id attribute value\n",
    "- key: the full tag \"k\" attribute value if no colon is present or the characters after the colon if one is.\n",
    "- value: the tag \"v\" attribute value\n",
    "- type: either the characters before the colon in the tag \"k\" value or \"regular\" if a colon\n",
    "        is not present.\n",
    "Additionally,\n",
    "- if the tag \"k\" value contains problematic characters, the tag should be ignored\n",
    "- if the tag \"k\" value contains a \":\" the characters before the \":\" should be set as the tag type\n",
    "  and characters after the \":\" should be set as the tag key\n",
    "- if there are additional \":\" in the \"k\" value they and they should be ignored and kept as part of\n",
    "  the tag key. For example:\n",
    "  <tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "  should be turned into\n",
    "  {'id': 12345, 'key': 'street:name', 'value': 'Lincoln', 'type': 'addr'}\n",
    "- If a node has no secondary tags then the \"node_tags\" field should just contain an empty list.\n",
    "The final return value for a \"node\" element should look something like:\n",
    "{'node': {'id': 757860928,\n",
    "          'user': 'uboot',\n",
    "          'uid': 26299,\n",
    "       'version': '2',\n",
    "          'lat': 41.9747374,\n",
    "          'lon': -87.6920102,\n",
    "          'timestamp': '2010-07-22T16:16:51Z',\n",
    "      'changeset': 5288876},\n",
    " 'node_tags': [{'id': 757860928,\n",
    "                'key': 'amenity',\n",
    "                'value': 'fast_food',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'cuisine',\n",
    "                'value': 'sausage',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'name',\n",
    "                'value': \"Shelly's Tasty Freeze\",\n",
    "                'type': 'regular'}]}\n",
    "### If the element top level tag is \"way\":\n",
    "The dictionary should have the format {\"way\": ..., \"way_tags\": ..., \"way_nodes\": ...}\n",
    "The \"way\" field should hold a dictionary of the following top level way attributes:\n",
    "- id\n",
    "- user\n",
    "- uid\n",
    "- version\n",
    "- timestamp\n",
    "- changeset\n",
    "All other attributes can be ignored\n",
    "The \"way_tags\" field should again hold a list of dictionaries, following the exact same rules as\n",
    "for \"node_tags\".\n",
    "Additionally, the dictionary should have a field \"way_nodes\". \"way_nodes\" should hold a list of\n",
    "dictionaries, one for each nd child tag.  Each dictionary should have the fields:\n",
    "- id: the top level element (way) id\n",
    "- node_id: the ref attribute value of the nd tag\n",
    "- position: the index starting at 0 of the nd tag i.e. what order the nd tag appears within\n",
    "            the way element\n",
    "The final return value for a \"way\" element should look something like:\n",
    "{'way': {'id': 209809850,\n",
    "         'user': 'chicago-buildings',\n",
    "         'uid': 674454,\n",
    "         'version': '1',\n",
    "         'timestamp': '2013-03-13T15:58:04Z',\n",
    "         'changeset': 15353317},\n",
    " 'way_nodes': [{'id': 209809850, 'node_id': 2199822281, 'position': 0},\n",
    "               {'id': 209809850, 'node_id': 2199822390, 'position': 1},\n",
    "               {'id': 209809850, 'node_id': 2199822392, 'position': 2},\n",
    "               {'id': 209809850, 'node_id': 2199822369, 'position': 3},\n",
    "               {'id': 209809850, 'node_id': 2199822370, 'position': 4},\n",
    "               {'id': 209809850, 'node_id': 2199822284, 'position': 5},\n",
    "               {'id': 209809850, 'node_id': 2199822281, 'position': 6}],\n",
    " 'way_tags': [{'id': 209809850,\n",
    "               'key': 'housenumber',\n",
    "               'type': 'addr',\n",
    "               'value': '1412'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street',\n",
    "               'type': 'addr',\n",
    "               'value': 'West Lexington St.'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:name',\n",
    "               'type': 'addr',\n",
    "               'value': 'Lexington'},\n",
    "              {'id': '209809850',\n",
    "               'key': 'street:prefix',\n",
    "               'type': 'addr',\n",
    "               'value': 'West'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:type',\n",
    "               'type': 'addr',\n",
    "               'value': 'Street'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building',\n",
    "               'type': 'regular',\n",
    "               'value': 'yes'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'levels',\n",
    "               'type': 'building',\n",
    "               'value': '1'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building_id',\n",
    "               'type': 'chicago',\n",
    "               'value': '366409'}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Your task is to use the iterative parsing to process the map file and\n",
    "find out not only what tags are there, but also how many, to get the\n",
    "feeling on how much of which data you can expect to have in the map.\n",
    "Fill out the count_tags function. It should return a dictionary with the \n",
    "tag name as the key and number of times this tag can be encountered in \n",
    "the map as value.\n",
    "\n",
    "Note that your code will be tested with a different data file than the 'example.osm'\n",
    "\"\"\"\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "\n",
    "def count_tags(filename):\n",
    "    xmlfile = open(filename,\"r\",1)\n",
    "    filecontents = ET.iterparse(xmlfile, events=(\"start\", \"end\"))\n",
    "    filecontents = iter(filecontents)\n",
    "    event,root = filecontents.next()\n",
    "    tags = {}\n",
    "    for event, elem in filecontents:\n",
    "        if(event == \"end\"):\n",
    "            tag = elem.tag\n",
    "            if(tag in tags.keys()):\n",
    "                tags[tag] += 1\n",
    "            else:\n",
    "                tags[tag] = 1\n",
    "            root.clear()\n",
    "    return tags\n",
    "\n",
    "def test():\n",
    "\n",
    "    tags = count_tags('tualatin.osm')\n",
    "    pprint.pprint(tags)\n",
    "    assert tags == {'bounds': 1,\n",
    "                     'member': 7459,\n",
    "                     'meta': 1,\n",
    "                     'nd': 264011,\n",
    "                     'node': 230350,\n",
    "                     'note': 1,\n",
    "                     'osm': 1,\n",
    "                     'relation': 238,\n",
    "                     'tag': 166213,\n",
    "                     'way': 28784}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 84751, 'lower_colon': 80351, 'other': 1111, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.ElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\"\"\"\n",
    "Your task is to explore the data a bit more.\n",
    "Before you process the data and add it into MongoDB, you should\n",
    "check the \"k\" value for each \"<tag>\" and see if they can be valid keys in MongoDB,\n",
    "as well as see if there are any other potential problems.\n",
    "We have provided you with 3 regular expressions to check for certain patterns\n",
    "in the tags. As we saw in the quiz earlier, we would like to change the data model\n",
    "and expand the \"addr:street\" type of keys to a dictionary like this:\n",
    "{\"address\": {\"street\": \"Some value\"}}\n",
    "So, we have to see if we have such tags, and if we have any tags with problematic characters.\n",
    "Please complete the function 'key_type'.\n",
    "\"\"\"\n",
    "\n",
    "OSMFILE = \"tualatin.osm\"\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        key = element.get(\"k\")\n",
    "        if problemchars.search(key):\n",
    "            keys['problemchars'] += 1\n",
    "        elif lower_colon.search(key):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif lower.search(key):\n",
    "            keys['lower'] += 1\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {'lower': 0, 'lower_colon': 0, 'problemchars': 0, 'other': 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "\n",
    "def test():\n",
    "    # You can use another testfile 'map.osm' to look at your solution\n",
    "    # Note that the assertions will be incorrect then.\n",
    "    keys = process_map(OSMFILE)\n",
    "    pprint.pprint(keys)\n",
    "    assert keys == {'lower': 84751, 'lower_colon': 80351, 'other': 1111, 'problemchars': 0}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "'''Cleaning up phone numbers'''\n",
    "\n",
    "OSMFILE = \"tualatin.osm\"\n",
    "\n",
    "def clean_phone(phonenumber):\n",
    "    phonePattern = re.compile(r'''(\\d{3})\\D*(\\d{3})\\D*(\\d{4})\\D*(\\d*)$''')\n",
    "    phonenumber = phonePattern.search(phonenumber).group()\n",
    "    phonenumber = re.sub(\" \", \"-\", phonenumber)\n",
    "    phonenumber = re.sub(\"[()]\", \"\", phonenumber)\n",
    "    if re.match(r'\\d{11}', phonenumber) is not None:\n",
    "        phonenumber = phone_num[1:10]\n",
    "    return phonenumber\n",
    "\n",
    "def audit(OSMFILE):\n",
    "    osm_file = open(OSMFILE, \"r\")\n",
    "    for event, elem in ET.iterparse(osm_file):\n",
    "        phonenumbers = set()\n",
    "        for tag in elem.iter(\"tag\"):\n",
    "            if tag.attrib['k'] == 'phone':\n",
    "                phonenumbers.add(clean_phone(tag.attrib['v']))\n",
    "    osm_file.close()\n",
    "    return phonenumbers\n",
    "\n",
    "\n",
    "def test():\n",
    "    phonenumbers = audit(OSMFILE)\n",
    "    pprint.pprint(phonenumbers)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your task in this exercise has two steps:\n",
    "\n",
    "- audit the OSMFILE and change the variable 'mapping' to reflect the changes needed to fix \n",
    "    the unexpected street types to the appropriate ones in the expected list.\n",
    "    You have to add mappings only for the actual problems you find in this OSMFILE,\n",
    "    not a generalized solution, since that may and will depend on the particular area you are auditing.\n",
    "- write the update_name function, to actually fix the street name.\n",
    "    The function takes a string with street name as an argument and should return the fixed name\n",
    "    We have provided a simple test so that you see what exactly is expected\n",
    "\"\"\"\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = \"tualatin.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Lane\", \"Road\", \"Loop\", \"Woods\",\n",
    "            \"Trail\", \"Parkway\", \"Circle\", \"Terrace\", \"Way\", \"Highway\", \"Path\"]\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Dr.\": \"Drive\",\n",
    "            \"Rd\": \"Road\"\n",
    "          }\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    name = name.split(' ')\n",
    "    type = name[-1]\n",
    "    if type in mapping:\n",
    "        name[-1] = mapping[type]\n",
    "        name = ' '.join(name)\n",
    "        return name\n",
    "\n",
    "def test():\n",
    "    st_types = audit(OSMFILE)\n",
    "    pprint.pprint(dict(st_types))\n",
    "    \n",
    "    for st_type, ways in st_types.iteritems():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            if name == \"SW Upper Boones Ferry Rd #100\":\n",
    "                better_name = \"SW Upper Boones Ferry Road #100\"\n",
    "            if name == \"SW 74th\":\n",
    "                better_name = \"SW 74th Avenue\"\n",
    "            if name == \"SW 91st\":\n",
    "                better_name = \"SW 91st Avenue\"\n",
    "            print name, \"=>\", better_name\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\"\"\"\n",
    "Your task is to explore the data a bit more.\n",
    "The first task is a fun one - find out how many unique users\n",
    "have contributed to the map in this particular area!\n",
    "The function process_map should return a set of unique user IDs (\"uid\")\n",
    "\"\"\"\n",
    "\n",
    "OSMFILE = \"tualatin.osm\"\n",
    "\n",
    "def get_user(element):\n",
    "    return\n",
    "\n",
    "def process_map(filename):\n",
    "    osm_file = open(filename, \"r\", 1)\n",
    "    context = ET.iterparse(osm_file, events=(\"start\", \"end\"))\n",
    "    context = iter(context)\n",
    "    users = set()\n",
    "    for event, elem in context:\n",
    "        if(event == \"end\"):\n",
    "            tag = elem.tag\n",
    "            if('user' in elem.attrib.keys()):\n",
    "                user = elem.attrib['user']\n",
    "                if(user != None and user not in users):\n",
    "                    users.add(user)\n",
    "    return users\n",
    "\n",
    "def test():\n",
    "    users = process_map(OSMFILE)\n",
    "    pprint.pprint(users)\n",
    "    assert len(users) == 123\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
